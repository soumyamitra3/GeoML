{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aee6b5b-0e7b-4fa1-a3f2-9b43741c21c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import rasterio.warp\n",
    "from rasterio.enums import Resampling\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from shapely.geometry import box\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b85fee-1642-4c13-be6b-8db456ca11bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error setting GDAL_DATA/PROJ_LIB: name 'gdal_data_path' is not defined\n",
      "Target CRS set to: EPSG:32643\n",
      "Target Resolution set to: 100 meters\n",
      "Attempting to read shapefile from: E:\\Hackathon\\GIS\\block.shp\n",
      "Master Grid Bounds derived from shapefile: [ 607128.26186922 1520302.09484182  796751.60625961 1743202.77801102]\n",
      "Master Grid Dimensions (pixels): Width=1896, Height=2229\n",
      "Master Grid Transform created.\n",
      "\n",
      "Master grid parameters initialized successfully!\n",
      "You can now proceed to the next cell to define the raster processing function.\n"
     ]
    }
   ],
   "source": [
    "# --- Define Master Grid Parameters --- These parameters will determine the common coordinate system, resolution and spatial extent for all input data.\n",
    "\n",
    "try:\n",
    "    if 'CONDA_PREFIX' in os.environ:\n",
    "        conda_prefix = os.environ['CONDA_PREFIX']\n",
    "        proj_lib_path = os.path.join(conda_prefix, 'Library', 'share', 'proj') # PROJ data files\n",
    "        \n",
    "        if os.path.exists(gdal_data_path):\n",
    "            os.environ['GDAL_DATA'] = gdal_data_path\n",
    "            print(f\"GDAL_DATA environment variable set to: {os.environ['GDAL_DATA']}\")\n",
    "        else:\n",
    "            print(f\"Warning: GDAL_DATA path not found at {gdal_data_path}. GDAL_DATA may still be unset.\")\n",
    "\n",
    "        if os.path.exists(proj_lib_path):\n",
    "            os.environ['PROJ_LIB'] = proj_lib_path\n",
    "            print(f\"PROJ_LIB environment variable set to: {os.environ['PROJ_LIB']}\")\n",
    "        else:\n",
    "            print(f\"Warning: PROJ_LIB path not found at {proj_lib_path}. PROJ_LIB may still be unset.\")\n",
    "    else:\n",
    "        print(\"Warning: CONDA_PREFIX not found in environment variables. GDAL_DATA and PROJ_LIB may not be set automatically.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error setting GDAL_DATA/PROJ_LIB: {e}\")\n",
    "\n",
    "# 1. Define the Target Coordinate Reference System (CRS)\n",
    "target_crs = 'EPSG:32643'                                                                          # User input\n",
    "print(f\"Target CRS set to: {target_crs}\")\n",
    "\n",
    "# 2. Define the Target Resolution (Cell Size)\n",
    "target_resolution = 100                                                                            # User input\n",
    "print(f\"Target Resolution set to: {target_resolution} meters\")\n",
    "\n",
    "# 3. Define the Spatial Extent of the Master Grid\n",
    "shapefile_path = r'E:\\Hackathon\\GIS\\block.shp'                                                     # User input\n",
    "print(f\"Attempting to read shapefile from: {shapefile_path}\")\n",
    "\n",
    "try:\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    gdf = gdf.to_crs(target_crs)\n",
    "    target_bounds = gdf.total_bounds  \n",
    "    print(f\"Master Grid Bounds derived from shapefile: {target_bounds}\")\n",
    "\n",
    "    dst_width = int((target_bounds[2] - target_bounds[0]) / target_resolution)\n",
    "    dst_height = int((target_bounds[3] - target_bounds[1]) / target_resolution)\n",
    "\n",
    "    master_transform = rasterio.transform.from_bounds(*target_bounds,\n",
    "                                                     width=dst_width,\n",
    "                                                     height=dst_height)\n",
    "    print(f\"Master Grid Dimensions (pixels): Width={dst_width}, Height={dst_height}\")\n",
    "    print(f\"Master Grid Transform created.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Shapefile not found at {shapefile_path}. Please check the path.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the shapefile: {e}\")\n",
    "    target_bounds = None \n",
    "    dst_width = 0\n",
    "    dst_height = 0\n",
    "    master_transform = None\n",
    "\n",
    "if target_bounds is not None:\n",
    "    master_grid_params = {\n",
    "        'target_crs': target_crs,\n",
    "        'target_resolution': target_resolution,\n",
    "        'target_bounds': target_bounds,\n",
    "        'dst_width': dst_width,\n",
    "        'dst_height': dst_height,\n",
    "        'master_transform': master_transform\n",
    "    }\n",
    "    print(\"\\nMaster grid parameters initialized successfully!\")\n",
    "    print(\"You can now proceed to the next cell to define the raster processing function.\")\n",
    "else:\n",
    "    master_grid_params = None # Indicate that initialization failed\n",
    "    print(\"\\nMaster grid parameters could not be fully initialized due to errors above.\")\n",
    "    print(\"Please resolve the errors (especially the shapefile path) before proceeding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e5aa3e-1da8-4a6b-8818-c27dcc2611da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature raster files to process:\n",
      " - E:\\\\Hackathon\\\\Geology\\\\norm_Lith_FeMn.tif\n",
      " - E:\\\\Hackathon\\\\Geology\\\\norm_gr_acfm.tif\n",
      " - E:\\\\Hackathon\\\\Geology\\\\norm_Line_density.tif\n",
      " - E:\\\\Hackathon\\\\Geology\\\\norm_Line_ring.tif\n",
      " - E:\\\\Hackathon\\\\Geology\\\\norm_intersect.tif\n",
      " - E:\\\\Hackathon\\\\Geology\\\\norm_gr_sch.tif\n",
      " - E:\\\\Hackathon\\\\Geology\\\\norm_vein.tif\n",
      " - E:\\\\Hackathon\\\\Geology\\\\norm_dyke.tif\n",
      " - E:\\\\Hackathon\\\\NGCM\\\\norm_pca1.tif\n",
      " - E:\\\\Hackathon\\\\Geophy\\\\normalized_BA.tif\n",
      " - E:\\\\Hackathon\\\\Geophy\\\\normalized_BA_res.tif\n",
      " - E:\\\\Hackathon\\\\Geophy\\\\normalized_BA_res_vdr.tif\n",
      " - E:\\\\Hackathon\\\\Geophy\\\\normalized_BA_tdr.tif\n",
      " - E:\\\\Hackathon\\\\Geophy\\\\normalized_BA_up5.tif\n",
      " - E:\\\\Hackathon\\\\Geophy\\\\normalized_MA.tif\n",
      " - E:\\\\Hackathon\\\\Geophy\\\\norm_MA_rtp.tif\n",
      " - E:\\\\Hackathon\\\\Geophy\\\\norm_MA_rtpres.tif\n",
      " - E:\\\\Hackathon\\\\Geophy\\\\normalized_MA_ana.tif\n",
      " - E:\\\\Hackathon\\\\Geophy\\\\normalized_MA_res.tif\n",
      " - E:\\\\Hackathon\\\\Geophy\\\\normalized_MA_up5.tif\n",
      " - E:\\\\Hackathon\\\\PGRS\\\\normalized_chl.tif\n",
      " - E:\\\\Hackathon\\\\PGRS\\\\norm_Silica.tif\n",
      " - E:\\\\Hackathon\\\\PGRS\\\\normalized_feo.tif\n",
      " - E:\\\\Hackathon\\\\PGRS\\\\normalized_mf.tif\n",
      "\n",
      "Target layer: E:\\\\Hackathon\\\\Target\\\\FeMn_target.tif\n",
      "\n",
      "Starting FEATURE raster processing...\n",
      "  Processing FEATURE layer 'norm_Lith_FeMn.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'norm_gr_acfm.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'norm_Line_density.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'norm_Line_ring.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'norm_intersect.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'norm_gr_sch.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'norm_vein.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'norm_dyke.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'norm_pca1.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'normalized_BA.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'normalized_BA_res.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'normalized_BA_res_vdr.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'normalized_BA_tdr.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'normalized_BA_up5.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'normalized_MA.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'norm_MA_rtp.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'norm_MA_rtpres.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'normalized_MA_ana.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'normalized_MA_res.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'normalized_MA_up5.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'normalized_chl.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'norm_Silica.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'normalized_feo.tif' with bilinear resampling.\n",
      "  Processing FEATURE layer 'normalized_mf.tif' with bilinear resampling.\n",
      "\n",
      "Starting TARGET layer processing...\n",
      "  Processing TARGET layer 'FeMn_target.tif' with NEAREST NEIGHBOR resampling.\n",
      "Target layer 'FeMn_target.tif' processed successfully.\n",
      "\n",
      "All rasters attempted to be processed.\n",
      "\n",
      "All processed rasters (features and target) have consistent lengths: 4226184\n",
      "Ready to combine data into a DataFrame and save to CSV.\n",
      "\n",
      "Processed data stored. You can now proceed to the next cell to create the final CSV.\n"
     ]
    }
   ],
   "source": [
    "# --- Define the process_raster function\n",
    "def process_raster(input_raster_path, master_grid_params, resampling_method=Resampling.bilinear, is_target_layer=False):\n",
    "    target_crs = master_grid_params['target_crs'] \n",
    "    target_transform = master_grid_params['master_transform'] \n",
    "    dst_width = master_grid_params['dst_width'] \n",
    "    dst_height = master_grid_params['dst_height'] \n",
    "\n",
    "    if is_target_layer:\n",
    "        chosen_resampling = Resampling.nearest \n",
    "        print(f\"  Processing TARGET layer '{os.path.basename(input_raster_path)}' with NEAREST NEIGHBOR resampling.\") \n",
    "    else:\n",
    "        chosen_resampling = resampling_method \n",
    "        print(f\"  Processing FEATURE layer '{os.path.basename(input_raster_path)}' with {chosen_resampling.name} resampling.\") \n",
    "\n",
    "    try:\n",
    "        with rasterio.open(input_raster_path) as src: \n",
    "            destination = np.zeros((dst_height, dst_width), dtype=src.profile['dtype']) \n",
    "\n",
    "            reproject_profile = src.profile.copy() \n",
    "            reproject_profile.update({\n",
    "                'crs': target_crs,\n",
    "                'transform': target_transform,\n",
    "                'width': dst_width,\n",
    "                'height': dst_height,\n",
    "                'driver': 'GTiff',\n",
    "                'dtype': src.profile['dtype']\n",
    "            }) #\n",
    "\n",
    "            rasterio.warp.reproject(\n",
    "                source=rasterio.band(src, 1), \n",
    "                destination=destination, \n",
    "                src_transform=src.transform, \n",
    "                src_crs=src.crs, \n",
    "                dst_transform=target_transform, \n",
    "                dst_crs=target_crs, \n",
    "                resampling=chosen_resampling, \n",
    "                num_threads=os.cpu_count() \n",
    "            )\n",
    "            return destination.flatten() \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {input_raster_path}: {e}\") \n",
    "        return None\n",
    "\n",
    "# --- List Your Input Raster Files ---\n",
    "target_layer_path = r'E:\\\\Hackathon\\\\Target\\\\FeMn_target.tif'                                   # User input\n",
    "\n",
    "feature_raster_files = [                                                                        # User input\n",
    "    r'E:\\\\Hackathon\\\\Geology\\\\norm_Lith_FeMn.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geology\\\\norm_gr_acfm.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geology\\\\norm_Line_density.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geology\\\\norm_Line_ring.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geology\\\\norm_intersect.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geology\\\\norm_gr_sch.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geology\\\\norm_vein.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geology\\\\norm_dyke.tif',\n",
    "    r'E:\\\\Hackathon\\\\NGCM\\\\norm_pca1.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geophy\\\\normalized_BA.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geophy\\\\normalized_BA_res.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geophy\\\\normalized_BA_res_vdr.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geophy\\\\normalized_BA_tdr.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geophy\\\\normalized_BA_up5.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geophy\\\\normalized_MA.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geophy\\\\norm_MA_rtp.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geophy\\\\norm_MA_rtpres.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geophy\\\\normalized_MA_ana.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geophy\\\\normalized_MA_res.tif',\n",
    "    r'E:\\\\Hackathon\\\\Geophy\\\\normalized_MA_up5.tif',\n",
    "    r'E:\\\\Hackathon\\\\PGRS\\\\normalized_chl.tif',\n",
    "    r'E:\\\\Hackathon\\\\PGRS\\\\norm_Silica.tif',\n",
    "    r'E:\\\\Hackathon\\\\PGRS\\\\normalized_feo.tif',\n",
    "    r'E:\\\\Hackathon\\\\PGRS\\\\normalized_mf.tif',\n",
    "]\n",
    "\n",
    "print(\"Feature raster files to process:\") \n",
    "for f in feature_raster_files:\n",
    "    print(f\" - {f}\") \n",
    "print(f\"\\nTarget layer: {target_layer_path}\") \n",
    "\n",
    "all_flattened_data = [] \n",
    "target_flattened_data = None \n",
    "\n",
    "if 'master_grid_params' not in locals() or master_grid_params is None:\n",
    "    print(\"\\nERROR: Master grid parameters were not initialized. Please go back to Step 1 and resolve the issues.\") \n",
    "else:\n",
    "    print(\"\\nStarting FEATURE raster processing...\") \n",
    "    for i, r_file in enumerate(feature_raster_files):\n",
    "        processed_array = process_raster(r_file, master_grid_params, resampling_method=Resampling.bilinear, is_target_layer=False) \n",
    "        if processed_array is not None:\n",
    "            all_flattened_data.append(processed_array) \n",
    "        else:\n",
    "            print(f\"Skipping {r_file} due to processing error.\") \n",
    "\n",
    "    print(\"\\nStarting TARGET layer processing...\") \n",
    "    target_flattened_data = process_raster(target_layer_path, master_grid_params, is_target_layer=True) \n",
    "    if target_flattened_data is not None:\n",
    "        print(f\"Target layer '{os.path.basename(target_layer_path)}' processed successfully.\") \n",
    "    else:\n",
    "        print(f\"ERROR: Target layer '{os.path.basename(target_layer_path)}' could not be processed.\") \n",
    "\n",
    "    print(\"\\nAll rasters attempted to be processed.\") \n",
    "\n",
    "    expected_length = master_grid_params['dst_width'] * master_grid_params['dst_height'] \n",
    "\n",
    "    if not all_flattened_data and target_flattened_data is None:\n",
    "        print(\"ERROR: No raster data (features or target) was successfully processed. Cannot create DataFrame.\") \n",
    "    elif target_flattened_data is None:\n",
    "        print(\"ERROR: Target layer was not processed successfully. Cannot create DataFrame.\") \n",
    "    elif len(all_flattened_data) > 0 and len(set(len(arr) for arr in all_flattened_data)) != 1:\n",
    "        print(\"\\nERROR: Feature data arrays have inconsistent lengths!\") #\n",
    "        print(\"Expected length (from master grid dimensions):\", expected_length) \n",
    "        for i, arr in enumerate(all_flattened_data):\n",
    "            print(f\"  Array from {feature_raster_files[i]}: Length = {len(arr)}\") \n",
    "        print(\"Please review your master grid parameters and feature raster files. Cannot proceed to CSV creation.\") \n",
    "    elif len(target_flattened_data) != expected_length:\n",
    "        print(f\"\\nERROR: Target layer array has inconsistent length! Expected {expected_length}, got {len(target_flattened_data)}.\") \n",
    "        print(\"Please review your master grid parameters and target raster file. Cannot proceed to CSV creation.\") \n",
    "    elif len(all_flattened_data) > 0 and len(all_flattened_data[0]) != expected_length:\n",
    "         print(f\"\\nERROR: First feature array length ({len(all_flattened_data[0])}) does not match expected length ({expected_length}).\") \n",
    "         print(\"Please review your master grid parameters and feature raster files. Cannot proceed to CSV creation.\") \n",
    "    else:\n",
    "        print(f\"\\nAll processed rasters (features and target) have consistent lengths: {expected_length}\") \n",
    "        print(\"Ready to combine data into a DataFrame and save to CSV.\") \n",
    "\n",
    "        processed_data_arrays = all_flattened_data + [target_flattened_data] \n",
    "        # FIX: Add the following line to define 'raster_files' for the next cell\n",
    "        raster_files = feature_raster_files + [target_layer_path] \n",
    "\n",
    "        print(\"\\nProcessed data stored. You can now proceed to the next cell to create the final CSV.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6e9cef-f704-4edc-96d3-9a337f84b1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensured output directory exists: E:\\\\Hackathon\\\\Model\\\\FeMn\n",
      "Output CSV will be saved to: E:\\\\Hackathon\\\\Model\\\\FeMn\\mineral_prospectivity_FeMn.csv\n",
      "\n",
      "Proceeding to create final DataFrame...\n",
      "X, Y coordinates DataFrame initialized.\n",
      "Adding predictor factors with names: ['norm_Lith_FeMn', 'norm_gr_acfm', 'norm_Line_density', 'norm_Line_ring', 'norm_intersect', 'norm_gr_sch', 'norm_vein', 'norm_dyke', 'norm_pca1', 'normalized_BA', 'normalized_BA_res', 'normalized_BA_res_vdr', 'normalized_BA_tdr', 'normalized_BA_up5', 'normalized_MA', 'norm_MA_rtp', 'norm_MA_rtpres', 'normalized_MA_ana', 'normalized_MA_res', 'normalized_MA_up5', 'normalized_chl', 'norm_Silica', 'normalized_feo', 'normalized_mf', 'FeMn_target']\n",
      "Final DataFrame created with 4226184 rows and 27 columns.\n",
      "Column order: ['X_Coordinate', 'Y_Coordinate', 'norm_Lith_FeMn', 'norm_gr_acfm', 'norm_Line_density', 'norm_Line_ring', 'norm_intersect', 'norm_gr_sch', 'norm_vein', 'norm_dyke', 'norm_pca1', 'normalized_BA', 'normalized_BA_res', 'normalized_BA_res_vdr', 'normalized_BA_tdr', 'normalized_BA_up5', 'normalized_MA', 'norm_MA_rtp', 'norm_MA_rtpres', 'normalized_MA_ana', 'normalized_MA_res', 'normalized_MA_up5', 'normalized_chl', 'norm_Silica', 'normalized_feo', 'normalized_mf', 'FeMn_target']\n",
      "Handled NoData values: Dropped 371132 rows containing NaN from factor columns.\n",
      "\n",
      "Final DataFrame successfully saved to: E:\\\\Hackathon\\\\Model\\\\FeMn\\mineral_prospectivity_FeMn.csv\n",
      "The CSV contains 3855052 rows and 27 columns.\n"
     ]
    }
   ],
   "source": [
    "output_directory = r'E:\\\\Hackathon\\\\Model\\\\FeMn'                                                  # User input\n",
    "output_csv_filename = 'mineral_prospectivity_FeMn.csv'                                            # User input\n",
    "\n",
    "os.makedirs(output_directory, exist_ok=True) \n",
    "print(f\"Ensured output directory exists: {output_directory}\") \n",
    "\n",
    "output_csv_path = os.path.join(output_directory, output_csv_filename) \n",
    "print(f\"Output CSV will be saved to: {output_csv_path}\") \n",
    "\n",
    "if 'processed_data_arrays' not in locals() or not processed_data_arrays:\n",
    "    print(\"ERROR: 'processed_data_arrays' not found or is empty. Please ensure Step 3 ran successfully.\") \n",
    "elif 'master_grid_params' not in locals() or master_grid_params is None:\n",
    "    print(\"ERROR: 'master_grid_params' not found or is None. Please ensure Step 1 ran successfully.\") \n",
    "elif 'raster_files' not in locals():\n",
    "    print(\"ERROR: 'raster_files' list (from Step 3) not found. Cannot automatically name columns.\") \n",
    "    print(\"Please ensure Step 3 ran successfully and 'raster_files' was defined.\") #\n",
    "else:\n",
    "    print(\"\\nProceeding to create final DataFrame...\") \n",
    "\n",
    "    # 2. Add X, Y Coordinates to the DataFrame FIRST\n",
    "    target_bounds = master_grid_params['target_bounds'] \n",
    "    target_resolution = master_grid_params['target_resolution'] \n",
    "    dst_width = master_grid_params['dst_width'] \n",
    "    dst_height = master_grid_params['dst_height'] \n",
    "\n",
    "    x_coords = np.linspace(target_bounds[0] + target_resolution / 2,\n",
    "                           target_bounds[2] - target_resolution / 2,\n",
    "                           dst_width) \n",
    "\n",
    "    y_coords = np.linspace(target_bounds[3] - target_resolution / 2,\n",
    "                           target_bounds[1] + target_resolution / 2,\n",
    "                           dst_height) \n",
    "\n",
    "    xv, yv = np.meshgrid(x_coords, y_coords) \n",
    "\n",
    "    # Create a DataFrame directly from the coordinates\n",
    "    df = pd.DataFrame({\n",
    "        'X_Coordinate': xv.flatten(),\n",
    "        'Y_Coordinate': yv.flatten()\n",
    "    }) \n",
    "    print(\"X, Y coordinates DataFrame initialized.\") \n",
    "\n",
    "    # 3. Add predictor factors to the DataFrame\n",
    "    column_names_factors = [os.path.splitext(os.path.basename(r_file))[0] for r_file in raster_files] #\n",
    "    print(f\"Adding predictor factors with names: {column_names_factors}\") \n",
    "    df_factors = pd.DataFrame(np.array(processed_data_arrays).T,\n",
    "                              columns=column_names_factors) \n",
    "    df = pd.concat([df, df_factors], axis=1) \n",
    "\n",
    "    print(f\"Final DataFrame created with {len(df)} rows and {df.shape[1]} columns.\") \n",
    "    print(f\"Column order: {df.columns.tolist()}\") \n",
    "\n",
    "\n",
    "    # 4. Handle NoData Values\n",
    "    initial_rows = len(df) \n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True) \n",
    "    df_factor_columns = column_names_factors #\n",
    "    df.dropna(subset=df_factor_columns, inplace=True) \n",
    "\n",
    "    print(f\"Handled NoData values: Dropped {initial_rows - len(df)} rows containing NaN from factor columns.\") \n",
    "\n",
    "    # 5. Save the DataFrame to the specified CSV file path\n",
    "    df.to_csv(output_csv_path, index=False) \n",
    "\n",
    "    print(f\"\\nFinal DataFrame successfully saved to: {output_csv_path}\") \n",
    "    print(f\"The CSV contains {len(df)} rows and {df.shape[1]} columns.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d3c4d-3636-4580-a515-3c4631776bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57792b9-6f43-42ac-bd4c-c4cc2239c2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e8aeb-2c40-4db6-8e3f-67845be58dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
